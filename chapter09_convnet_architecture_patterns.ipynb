{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1NuzW6IjPNa"
      },
      "source": [
        "## ConvNet architecture patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXF-8aH9jPNa"
      },
      "source": [
        "### Modularity, hierarchy, and reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7JGCUd-jPNa"
      },
      "source": [
        "### Residual connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuAHCUJZjPNa"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1)(residual)\n",
        "x = layers.add([x, residual])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ9kL5G5jPNa"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
        "x = layers.add([x, residual])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvIjFTqQjPNa"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "\n",
        "def residual_block(x, filters, pooling=False):\n",
        "    residual = x\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    if pooling:\n",
        "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "    elif filters != residual.shape[-1]:\n",
        "        residual = layers.Conv2D(filters, 1)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "    return x\n",
        "\n",
        "x = residual_block(x, filters=32, pooling=True)\n",
        "x = residual_block(x, filters=64, pooling=True)\n",
        "x = residual_block(x, filters=128, pooling=False)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn4GOe9DjPNb"
      },
      "source": [
        "### Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFb2sx6DjPNb"
      },
      "source": [
        "### Depthwise separable convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLJ4zq7-jPNb"
      },
      "source": [
        "### Putting it together: A mini Xception-like model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0xbCRTVjPNb"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlDy5Ku2jPNb",
        "outputId": "1c7eaf8d-98b6-4870-d940-fa4d97d6b653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/dogs-vs-cats...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 812M/812M [00:38<00:00, 22.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "download_path = kagglehub.competition_download(\"dogs-vs-cats\")\n",
        "\n",
        "with zipfile.ZipFile(download_path + \"/train.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ONPMZZjPNb",
        "outputId": "096274a8-7419-4a35-ec26-3ff894fd4223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, pathlib\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"dogs_vs_cats_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)\n",
        "\n",
        "batch_size = 64\n",
        "image_size = (180, 180)\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvmKaEqpjPNb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "\n",
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.2),\n",
        "]\n",
        "\n",
        "def data_augmentation(images, targets):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images, targets\n",
        "\n",
        "augmented_train_dataset = train_dataset.map(\n",
        "    data_augmentation, num_parallel_calls=8\n",
        ")\n",
        "augmented_train_dataset = augmented_train_dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtYukh0FjPNb"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "for size in [32, 64, 128, 256, 512]:\n",
        "    residual = x\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    residual = layers.Conv2D(\n",
        "        size, 1, strides=2, padding=\"same\", use_bias=False\n",
        "    )(residual)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hihjVbAVjPNb",
        "outputId": "99dab44c-a009-4629-e40d-fcb6482f3897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.5645 - loss: 0.6989 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 440ms/step - accuracy: 0.6110 - loss: 0.6624 - val_accuracy: 0.5010 - val_loss: 0.6939\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 452ms/step - accuracy: 0.6220 - loss: 0.6334 - val_accuracy: 0.5140 - val_loss: 0.6930\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.6178 - loss: 0.6373 - val_accuracy: 0.5000 - val_loss: 0.6997\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.6873 - loss: 0.5979 - val_accuracy: 0.5000 - val_loss: 0.6966\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 458ms/step - accuracy: 0.6722 - loss: 0.6157 - val_accuracy: 0.5000 - val_loss: 0.7154\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 455ms/step - accuracy: 0.7110 - loss: 0.5708 - val_accuracy: 0.5000 - val_loss: 0.7308\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 446ms/step - accuracy: 0.7369 - loss: 0.5511 - val_accuracy: 0.5000 - val_loss: 0.7291\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 441ms/step - accuracy: 0.7463 - loss: 0.5106 - val_accuracy: 0.5000 - val_loss: 0.7111\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 450ms/step - accuracy: 0.7461 - loss: 0.5147 - val_accuracy: 0.5000 - val_loss: 0.7916\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 434ms/step - accuracy: 0.7556 - loss: 0.5060 - val_accuracy: 0.5000 - val_loss: 0.8101\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 448ms/step - accuracy: 0.7753 - loss: 0.4747 - val_accuracy: 0.5000 - val_loss: 0.8921\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 434ms/step - accuracy: 0.7467 - loss: 0.5118 - val_accuracy: 0.5190 - val_loss: 0.8306\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 441ms/step - accuracy: 0.7890 - loss: 0.4491 - val_accuracy: 0.5390 - val_loss: 0.7672\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.7753 - loss: 0.4711 - val_accuracy: 0.5800 - val_loss: 0.6854\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 446ms/step - accuracy: 0.7982 - loss: 0.4350 - val_accuracy: 0.5220 - val_loss: 1.2751\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.7806 - loss: 0.4606 - val_accuracy: 0.6260 - val_loss: 0.7112\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 440ms/step - accuracy: 0.8018 - loss: 0.4267 - val_accuracy: 0.6780 - val_loss: 0.6131\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 481ms/step - accuracy: 0.8142 - loss: 0.4235 - val_accuracy: 0.6680 - val_loss: 0.7578\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 435ms/step - accuracy: 0.8341 - loss: 0.3806 - val_accuracy: 0.6790 - val_loss: 0.7002\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.8239 - loss: 0.3914 - val_accuracy: 0.7320 - val_loss: 0.5808\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 440ms/step - accuracy: 0.8394 - loss: 0.3612 - val_accuracy: 0.7480 - val_loss: 0.5444\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 445ms/step - accuracy: 0.8203 - loss: 0.3748 - val_accuracy: 0.7860 - val_loss: 0.4482\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.8254 - loss: 0.3875 - val_accuracy: 0.7930 - val_loss: 0.4662\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.8405 - loss: 0.3560 - val_accuracy: 0.7440 - val_loss: 0.5737\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 445ms/step - accuracy: 0.8554 - loss: 0.3277 - val_accuracy: 0.7280 - val_loss: 0.6722\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 441ms/step - accuracy: 0.8504 - loss: 0.3398 - val_accuracy: 0.7570 - val_loss: 0.5882\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.8478 - loss: 0.3270 - val_accuracy: 0.7380 - val_loss: 0.7005\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 435ms/step - accuracy: 0.8719 - loss: 0.3113 - val_accuracy: 0.7050 - val_loss: 0.7179\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 462ms/step - accuracy: 0.8577 - loss: 0.3330 - val_accuracy: 0.8320 - val_loss: 0.4183\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 471ms/step - accuracy: 0.8852 - loss: 0.2722 - val_accuracy: 0.7720 - val_loss: 0.4843\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 449ms/step - accuracy: 0.8771 - loss: 0.3079 - val_accuracy: 0.7590 - val_loss: 0.4837\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 443ms/step - accuracy: 0.8535 - loss: 0.3243 - val_accuracy: 0.6840 - val_loss: 0.8020\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 440ms/step - accuracy: 0.8797 - loss: 0.2772 - val_accuracy: 0.7690 - val_loss: 0.4935\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 434ms/step - accuracy: 0.8850 - loss: 0.2782 - val_accuracy: 0.7380 - val_loss: 0.6776\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 439ms/step - accuracy: 0.8878 - loss: 0.2610 - val_accuracy: 0.7790 - val_loss: 0.5610\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 444ms/step - accuracy: 0.8711 - loss: 0.2833 - val_accuracy: 0.8390 - val_loss: 0.3871\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 439ms/step - accuracy: 0.8965 - loss: 0.2492 - val_accuracy: 0.7160 - val_loss: 0.9036\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 457ms/step - accuracy: 0.8854 - loss: 0.2798 - val_accuracy: 0.8090 - val_loss: 0.4609\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 448ms/step - accuracy: 0.8907 - loss: 0.2763 - val_accuracy: 0.7520 - val_loss: 0.5715\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 453ms/step - accuracy: 0.9062 - loss: 0.2325 - val_accuracy: 0.7830 - val_loss: 0.5917\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 450ms/step - accuracy: 0.9053 - loss: 0.2445 - val_accuracy: 0.8250 - val_loss: 0.4030\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 501ms/step - accuracy: 0.8936 - loss: 0.2555 - val_accuracy: 0.7170 - val_loss: 0.7233\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 435ms/step - accuracy: 0.9112 - loss: 0.2371 - val_accuracy: 0.7970 - val_loss: 0.5446\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 439ms/step - accuracy: 0.9078 - loss: 0.2213 - val_accuracy: 0.7200 - val_loss: 0.8467\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 460ms/step - accuracy: 0.9071 - loss: 0.2197 - val_accuracy: 0.7120 - val_loss: 0.6997\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 448ms/step - accuracy: 0.8899 - loss: 0.2431 - val_accuracy: 0.8350 - val_loss: 0.3493\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.9039 - loss: 0.2354 - val_accuracy: 0.7710 - val_loss: 0.5765\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 447ms/step - accuracy: 0.9099 - loss: 0.2128 - val_accuracy: 0.8300 - val_loss: 0.4263\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.9210 - loss: 0.1960 - val_accuracy: 0.8050 - val_loss: 0.5129\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 462ms/step - accuracy: 0.9113 - loss: 0.2216 - val_accuracy: 0.8330 - val_loss: 0.4257\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 431ms/step - accuracy: 0.9218 - loss: 0.1913 - val_accuracy: 0.8570 - val_loss: 0.3960\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 452ms/step - accuracy: 0.9171 - loss: 0.1964 - val_accuracy: 0.8240 - val_loss: 0.4394\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 463ms/step - accuracy: 0.9256 - loss: 0.1901 - val_accuracy: 0.7670 - val_loss: 0.6452\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 471ms/step - accuracy: 0.9326 - loss: 0.1709 - val_accuracy: 0.8160 - val_loss: 0.5004\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 443ms/step - accuracy: 0.9284 - loss: 0.1736 - val_accuracy: 0.8100 - val_loss: 0.4714\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9267 - loss: 0.1859 - val_accuracy: 0.7670 - val_loss: 0.6320\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 450ms/step - accuracy: 0.9348 - loss: 0.1543 - val_accuracy: 0.8330 - val_loss: 0.4017\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9360 - loss: 0.1621 - val_accuracy: 0.8570 - val_loss: 0.3766\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 442ms/step - accuracy: 0.9352 - loss: 0.1626 - val_accuracy: 0.8520 - val_loss: 0.3917\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 443ms/step - accuracy: 0.9446 - loss: 0.1633 - val_accuracy: 0.8090 - val_loss: 0.6125\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 461ms/step - accuracy: 0.9333 - loss: 0.1608 - val_accuracy: 0.8480 - val_loss: 0.4042\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 441ms/step - accuracy: 0.9386 - loss: 0.1475 - val_accuracy: 0.7480 - val_loss: 1.1684\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 427ms/step - accuracy: 0.9469 - loss: 0.1613 - val_accuracy: 0.8640 - val_loss: 0.3760\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9515 - loss: 0.1414 - val_accuracy: 0.8720 - val_loss: 0.3799\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.9512 - loss: 0.1394 - val_accuracy: 0.8100 - val_loss: 0.5504\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 428ms/step - accuracy: 0.9331 - loss: 0.1728 - val_accuracy: 0.8550 - val_loss: 0.4151\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 442ms/step - accuracy: 0.9412 - loss: 0.1521 - val_accuracy: 0.7810 - val_loss: 0.5620\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 443ms/step - accuracy: 0.9378 - loss: 0.1638 - val_accuracy: 0.8640 - val_loss: 0.3827\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 438ms/step - accuracy: 0.9377 - loss: 0.1497 - val_accuracy: 0.8390 - val_loss: 0.5114\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 450ms/step - accuracy: 0.9551 - loss: 0.1292 - val_accuracy: 0.8780 - val_loss: 0.3503\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 450ms/step - accuracy: 0.9607 - loss: 0.1108 - val_accuracy: 0.8590 - val_loss: 0.4867\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 437ms/step - accuracy: 0.9310 - loss: 0.1695 - val_accuracy: 0.8270 - val_loss: 0.5399\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 441ms/step - accuracy: 0.9370 - loss: 0.1566 - val_accuracy: 0.8600 - val_loss: 0.4156\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 459ms/step - accuracy: 0.9553 - loss: 0.1136 - val_accuracy: 0.8470 - val_loss: 0.5360\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 476ms/step - accuracy: 0.9550 - loss: 0.1209 - val_accuracy: 0.8610 - val_loss: 0.3697\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 465ms/step - accuracy: 0.9578 - loss: 0.1259 - val_accuracy: 0.8010 - val_loss: 0.6493\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 471ms/step - accuracy: 0.9626 - loss: 0.1028 - val_accuracy: 0.8120 - val_loss: 0.6051\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 462ms/step - accuracy: 0.9407 - loss: 0.1628 - val_accuracy: 0.7110 - val_loss: 1.4593\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 456ms/step - accuracy: 0.9582 - loss: 0.1164 - val_accuracy: 0.8330 - val_loss: 0.6441\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 444ms/step - accuracy: 0.9647 - loss: 0.0973 - val_accuracy: 0.8340 - val_loss: 0.5543\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 465ms/step - accuracy: 0.9512 - loss: 0.1344 - val_accuracy: 0.8480 - val_loss: 0.5128\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 460ms/step - accuracy: 0.9470 - loss: 0.1435 - val_accuracy: 0.8450 - val_loss: 0.4544\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 461ms/step - accuracy: 0.9482 - loss: 0.1282 - val_accuracy: 0.8150 - val_loss: 0.6429\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 468ms/step - accuracy: 0.9658 - loss: 0.0951 - val_accuracy: 0.8330 - val_loss: 0.6517\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 460ms/step - accuracy: 0.9443 - loss: 0.1458 - val_accuracy: 0.8420 - val_loss: 0.4446\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.9635 - loss: 0.1199 - val_accuracy: 0.8290 - val_loss: 0.5605\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 447ms/step - accuracy: 0.9556 - loss: 0.1238 - val_accuracy: 0.8430 - val_loss: 0.4012\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 459ms/step - accuracy: 0.9668 - loss: 0.1000 - val_accuracy: 0.8710 - val_loss: 0.3881\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 453ms/step - accuracy: 0.9619 - loss: 0.0959 - val_accuracy: 0.8640 - val_loss: 0.4780\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 464ms/step - accuracy: 0.9460 - loss: 0.1172 - val_accuracy: 0.8310 - val_loss: 0.6131\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 456ms/step - accuracy: 0.9562 - loss: 0.1043 - val_accuracy: 0.8810 - val_loss: 0.4533\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.9596 - loss: 0.1015 - val_accuracy: 0.8630 - val_loss: 0.4219\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 461ms/step - accuracy: 0.9600 - loss: 0.1015 - val_accuracy: 0.8400 - val_loss: 0.4601\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 472ms/step - accuracy: 0.9590 - loss: 0.1067 - val_accuracy: 0.8590 - val_loss: 0.4657\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.9600 - loss: 0.1018 - val_accuracy: 0.8540 - val_loss: 0.5156\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.9557 - loss: 0.1062 - val_accuracy: 0.8820 - val_loss: 0.3234\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 445ms/step - accuracy: 0.9605 - loss: 0.0930 - val_accuracy: 0.8700 - val_loss: 0.3579\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 473ms/step - accuracy: 0.9689 - loss: 0.0868 - val_accuracy: 0.8800 - val_loss: 0.3408\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9677 - loss: 0.0852 - val_accuracy: 0.8450 - val_loss: 0.4568\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    augmented_train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}